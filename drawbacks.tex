\section{Drawbacks}

\subsection{Scope}

Collective Intelligence has been applied outside of simple information processing; however, its applications are generally limited to tasks where the participants have relatively low communication. Even if communication is technically involved, it is relatively cursory and task-oriented. Real social interaction is not really included.

Further, entrenched social factors are not really included. This means that while collective intelligence might be a good level of analysis for an idealized group, or for a general group, it may miss a lot of the detail involved in a specific group. While a group may behave like a general group at certain times in toy tasks, in a workplace, where social relations and common practice have built up over years, they are likely to have many factors that are not covered by the theory. 

This makes the scope of Collective Intelligence to at least partially be restricted to toy tasks. Of course, with the advent of crowdsourcing, toy tasks with little communication and very little complicated social factors are very common. 

\subsection{Ethical}

From an ethical standpoint, the types of tasks that Collective Intelligence is often interested in (crowdsourcing) has a few dilemmas. In directed crowdsourcing, as discussed earlier, workers are recruited for small amounts of money to perform simple tasks. Normally, they are paid based on task completion, rather than an hourly wage, which allows this type of work to avoid minimum wage laws. This places the workers who complete such tasks in a similar group as migrant farmworkers or sweatshop workers. However, since the tasks are often over the Internet, this problem may not render itself apparent to the organizer of the task: he or she likely never even meets the people working for him or her. 

On the other side of the spectrum, the types of tasks involved in passive crowdsourcing offer different kinds of problems. While the data is hopefully not individually identifiable, it is still data that is being collected for use in some type of research. Most likely, this is done without the user's consent and the user is also not compensated. While the controversial Facebook study had experimental manipulation \cite{facebook1}, there has been controversy over researchers that simply used publicly generated data \cite{facebook2}. While this problem is not limited to Collective Intelligence, it is applicable to many types of CI-at-scale research.  

\subsection{Cognitive}

While Collective Intelligence theoretically could make use of the full range of the cognitive capabilities of a human, that is generally not the case. Many crowdsourcing tasks rely on fairly rote procedures. For instance, the Find-Fix-Verify paradigm discussed earlier takes the complex task of writing and breaks it into tasks that are fairly simple on their own. Then, it has each person perform one of these fairly simple tasks. Other common tasks, such as image labeling, have each person perform a task that even algorithms can generally perform correctly. In few of the tasks, the full power of human cognitive abilities is used.

Paradigms like ACT-R \cite{actr} generally rely on people's innate ability to learn. While simpler formulations have been criticized as only modeling expert behavior, the cognitive paradigm has largely moved beyond that. Collective Intelligence as a theory, however, is largely rooted in the same type of toy tasks that make up IQ tests. These tasks generally are designed such that learning has little or no effect, because the goal is for a person's IQ score to remain more or less constant, regardless of their experience. However, this construction ignores one of the most fundamentally powerful pieces of human intelligence. 